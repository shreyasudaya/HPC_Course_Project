\documentclass[journal, a4paper]{IEEEtran}
\usepackage{graphicx,color,amssymb,amsmath,framed,clrscode,amsthm,  epstopdf, epsfig, enumerate, url}
\usepackage{balance}
\usepackage{cite}
%	\usepackage{algorithm}
%\usepackage{algpseudocode}
%\usepackage[dvisvgm, usenames, dvipsnames]{color}

\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage[font=scriptsize]{caption}
\usepackage[font=scriptsize]{subcaption}
%\usepackage{amsmath,amssymb,amsfonts}
\usepackage{csquotes}
\usepackage{paralist}
%\usepackage{multicol}
%\usepackage{lineno} 
\usepackage[switch]{lineno}
%\usepackage{flushend}



\usepackage{xcolor}


\pagestyle{empty}
%\usepackage{algorithm, algorithmic}
%\usepackage{algpseudocode}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
%\setcounter{AlgoLine}{29}

\begin{document}
	
	\title{Analysis of Parallelized Memory Algorithms in High Performance Computing}
	
	%	\title{Energy Harvesting}
	%	\author{Prathyusha M R, JRF CSE Dept}
	%	\date{July 2022}
	
	
	
	% make the title area
	\maketitle
	
	% As a general rule, do not put math, special symbols or citations
	% in the abstract or keywords.
%	\begin{abstract}
%		In recent years, the Internet of Things (IoT) has grown exponentially as more and more items are connected to the internet. The development of the IoT has been facilitated by the confluence of numerous technologies, including ubiquitous computing, affordable sensors, embedded systems, and machine learning. Energy is a crucial resource for powering IoT devices, with batteries being a significant energy source. However, battery maintenance has become a major limitation. Harvesting energy from the ambient environment is one of the solutions to overcome this limitation. Consequently, batteryless energy-harvesting IoT devices (also called EH-IoTs) are exploring the market to autonomously power the devices. This study examines a detailed state-of-the-art about the IoT from the first IoT products to recent applications. First, the fundamentals of IoT architecture and its characteristics are explained, then IoT connectivity and related technologies are discussed. Various energy sources for IoT systems are explored. Major emphasis is given to energy harvesting schemes over battery-powered IoT systems. Next, a set of energy harvesting techniques suggested recently are analyzed. Finally, we examine various IoT applications, challenges, and potential future research directions.
		
		
%	\end{abstract}
	
	% Note that keywords are not normally used for peerreview papers.
%	\begin{IEEEkeywords}
	%	Internet of Things; IoT Technologies; IoT Applications; Energy Sources for IoT; IoT Challenges.
%	\end{IEEEkeywords}
	
	
	
	
	
	
	
	% page as needed:
	% \ifCLASSOPTIONpeerreview
	% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
	% \fi
	%
	% For peerreview papers, this IEEEtran command inserts a page break and
	% creates the second title. It will be ignored for other modes.
	\IEEEpeerreviewmaketitle
	
	
	
	
	\maketitle
	
	\thispagestyle{empty}
	\section{Introduction}

	Remote sensing technologies have led to an increase in geospatial data collection and resolution, necessitating more efficient computational algorithms for processing big GIS data. This data is crucial for hydrological, topographic analysis, environmental modeling, and Earth surface simulation. These models aid in understanding complex environmental interactions, facilitating informed decision-making and policy formulation. Several algorithms are developed to support computational task in environmental modeling. However, as data size increases, it becomes impractical to calculate this parameter on a single computer that is using serial algorithm \cite{CHO2023105771,KOTYRA2023105728}.
	
	Researchers in geospatial data processing have explored parallel algorithms to improve computational efficiency. Parallel programming allows high-performance applications to utilize modern parallel hardware, including shared-memory architectures like multicores and NUMA of multicores, and distributed-memory architectures like clusters. The complexity of hardware has increased with out-of-order computing capabilities, memory hierarchies, and smart network interface cards used as co-processors for networking tasks \cite{LOFF2021743}.
	
	Parallel algorithms are used to improve computational efficiency by breaking down complex problems into manageable tasks that can be executed simultaneously using multiple processors. Techniques include OpenMP, MPI, GPGPU, and Asynchronous Many-Tasks. OpenMP is a widely used framework for parallel programming. It provides directives for shared-memory parallelism, enabling developers to create efficient and scalable parallel algorithms \cite{KOTYRA2023105728}.
	
	OpenMP is the standard application programming interface for
	shared memory parallel computing. By providing a set of compiler directives, runtime library functions, and environment variables, it makes the process of parallelizing code easier. The splitting of work among several threads, with each thread executing a portion of the code concurrently, is the fundamental idea behind OpenMP. Coordinated access to shared memory allows threads to work together effectively. This framework is especially useful for making the most of the parallel capabilities of contemporary multi-core processors, which improves the efficiency of algorithms and applications in a variety of fields \cite{chapman2007using}.
	
	The flow accumulation algorithm is a crucial tool in hydrology and GIS for understanding surface water movement. It calculates flow accumulation in a rasterized topographical model, determining the total upstream contributing area to each cell in a digital elevation model. This method helps identify primary flow paths within a watershed and is essential for flood prediction, watershed management, and terrain analysis. Its sophisticated variations and adaptations continually refine our understanding of surface water behavior in diverse terrains \cite{CHO2023105771,KOTYRA2023105728}.
	
	However, parallelization of flow accumulation tasks remains challenging due to spatial dependency and global computation. There is a need to reduce memory requirements for processing large datasets on a single computer.
	
	
	\section{Literature Survey} 
	\label{sec: ls}
	
	Kotyra \textit{et al.} \cite{KOTYRA2021104741} developed a faster method for calculating flow accumulation, resulting in shorter execution times. They discussed two approaches in parallelizing flow accumulation algorithms: the bottom-up approach and the top-down approach. The study compared six flow accumulation algorithms in sequential, parallel, and task-based implementations, using 118 different data sets. The top-down algorithm was found to be the fastest, with an average execution time of less than 30 seconds. The parallel top-down implementation was the most suitable for flow accumulation calculations. The task-based top-down implementation was less efficient, with an average processing time of 21.1\% longer for subcatchments and 32.7\% longer for rectangular frames. The algorithm's linear time complexity was measured in various settings, including frame 58 and frame 17 with 240 threads per core. The results showed a strong relationship between the number of cores used and the speedup compared to the sequential version, indicating that increasing the number of cores up to 60 still reduces the average computation time.

	Jong \textit{et al.} \cite{DEJONG2022105083} parallelized and distributed the set of flow accumulation algorithms to determine how the material flows downstream. They used the asynchronous many-task (AMT) approach for parallel and concurrent computations, avoiding synchronization points and promoting composability of modelling operations. The AMT-based algorithms were evaluated for performance, scalability, and composability. It is observed that they can efficiently use additional hardware and perform well when combined with other operations. However, further research is needed to optimize the algorithms for specific hardware architectures and evaluate their performance on larger datasets. The limitation is that the performance of the algorithms was evaluated on a limited set of datasets and that further research is needed to analyze the impact of different hardware architectures, programming languages, flow direction algorithms, and scheduling strategies.
	
	Kotyra \textit{et al.} \cite{KOTYRA2023105728} designed seven fast raster-based algorithms for finding the longest flow paths in flow direction grids using a linear time complexity approach. The algorithms were evaluated using eight large datasets, generated using a hydrological model, and compared with existing GIS software. The algorithms achieved significant speedups, up to 30 times faster on Windows and 17 times faster on Ubuntu, depending on the dataset and algorithm used. The authors concluded that their approach was effective in achieving fast and accurate results for finding the longest flow paths in flow direction grids. However, they noted that their approach is based on raster data and assumes a steady-state flow regime, which may not be applicable to unsteady flow conditions. Future research should explore the development of algorithms based on more complex models and the scalability and portability of their algorithms to other platforms and architectures.
	
	Cho \textit{et al.} \cite{CHO2020104774} suggested longest flow path algorithm which compute few rasters that reduce computational time and improves efficiency. The algorithm is based on depth-first search and breadth-first search, and using equations derived from Hack's law to estimate the longest flow length. The algorithm also employs a branching strategy to eliminate inferior neighbor cells and speed up traversal. The suggested method is evaluated through benchmark experiments conducted in Georgia and Texas, comparing the performance of the algorithm with the Arc Hydro Longest Flow Path tool for ArcGIS Pro. The results showed that the algorithm's performance is affected by disk type and memory size, with solid-state drives and larger memory sizes resulting in faster computation times. The authors conclude that the proposed algorithm is a valuable addition to environmental modelling and software. One limitation is that the experiments were conducted on a limited set of data from two states in the United States, and the results may not be generalizable to other regions or datasets. 

	Stojanovic \textit{et al.} \cite{stojanovic2020accelerating} suggested accelerating the flow distribution phase using MPI on a cluster. The author suggested the parallelization of the flow distribution computation phase of the watershed analysis algorithm using MPI. Two different MPI implementations were proposed and the advantages and shortcomings of both parallel implementations	are analyzed. The experimental evaluation is conducted on several large DEM datasets and varying numbers of computers in the cluster. They observed the approach that overlaps process computing and communication achieves the best results. The proposed MPI solutions are effective in accelerating the flow accumulation step of watershed analysis. The speedup using MPI is significant compared to sequential execution. While these are effective, other methods are not considered and neither are other libraries such as OpenMP or CUDA.
	
	Lal \textit{et al.} \cite{10.1007/978-3-030-60939-9_16} presented a quantitative analysis on the caches for memory divergent workloads simulated by gpgpu-sim. Increasing the size of the L1 data cache improved the spatial locality, while increasing for L2 improved temporal locally. They analyzed the impact of parameters like block size and thread count on the algorithm's performance and optimized it on different hardware configurations. The evaluation is based on benchmarks run on an NVIDIA GPU, focusing on data locality in GPU caches for memory-divergent workloads. The study shows higher inter-warp hits (46\%) at the L1 cache for memory-divergent workloads compared to the state-of-the-art. However, about 50\% of cache capacity and other scarce resources are wasted due to data over-fetch. However, the limitation include its focus on NVIDIA GPU architectures, its limited application to other types of workloads, and its inability to consider other potential performance bottlenecks.
	
	Kotyra \textit{et al.} \cite{KOTYRA2023105613} proposed a fast watershed delineation algorithm for GPU that uses CUDA and OpenMP. The algorithm iteratively processes each cell in the flow direction raster, identifying its downstream neighbor and checking if it belongs to the same catchment area. It includes optimizations to reduce memory usage and improve performance. The algorithm outperformed traditional GIS software packages in terms of speed and efficiency. The main loop of the algorithm, which repeatedly invokes the GPU kernel, accounts for only 28.8\% of the total execution time on average. Data transfers account for 34.5\% of the total time on average. The algorithm's performance is affected by the choice of hardware and software platforms, and its implementation may require specialized knowledge in parallel programming and GPU computing.
	
	Huang \textit{et al.} \cite{HUANG2022106} discussed a comprehensive study of in-memory computing.	They covered software performance, usability, robustness, and portability. An in-depth analysis is conducted on the evolution of in-memory computing. The authors suggested commit history for two in-memory libraries and observed most of the commits	were towards performance maintenance, suggesting it has a significant role towards computation. The in-memory computing has better performance than traditional post-processing. The in-memory computing is performed with regard to its software evolution, 	performance, usability, robustness, and portability. The results suggest that in-memory computing offers much higher scalability and performance than the traditional post-processing.
	
	\bibliographystyle{ieeetr}
	\bibliography{reference}

\end{document}